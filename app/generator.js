'use strict';

import faker from 'faker';
import Chance from 'chance';
import yaml from 'yamljs';
import path from 'path';
import fs from 'fs';
import archiver from 'archiver';
const chance = new Chance();
// import couchbase from 'couchbase';

const defaults = {
  models: '',
  number: 1,
  zip: '',
  server: '127.0.0.1',
  bucket: 'default',
  password: ''
};
let models = {}; // global variable to hold parsed models
let model_order = []; // global variable to hold the model run order
let model_count = 0; // global variable to hold the number of available models

let settings = {}; // global variable to hold the options + defaults

const documents = {}; // global variable to keep track of the generated documents
let documents_counter = 0; // global variable hold the total number of documents generated
let globals = {}; // a global variable to allow saving of values generated by models

let archive, archive_out; // global variable to hold zip references
let archive_entries_added = 0;
let archive_entries_processed = 0;

const start = (options = defaults) => new Promise((resolve, reject) => {
  try {
    // console.log('start');
    setup(options, resolve, reject)
      .then(get_models)
      .then(load_models)
      .then(parse_models)
      .then(resolve_dependencies)
      .then(generate)
      .catch((err) => {
        error_cleanup()
          .then(() => {
            reject(err);
          });
      });
  } catch (e) {
    console.log('Error: start', e);
    reject(e);
  }
});

// error cleanup to delete generated files, etc.
const error_cleanup = () => new Promise((resolve, reject) => {
  // console.log('error_cleanup');
  try {
    if (settings.zip) {
      // prevent the close method from being called to the generation is not resolved
      archive_out.removeAllListeners('close');
      // attach a new close event to delete the zip file
      archive_out.on('close', () => {
        fs.unlink(archive_out.path, (err) => {
          if (err) {
            reject(err);
          } else {
            resolve();
          }
        });
      });
    }
  } catch (e) {
    reject(e);
  }
});

// pre run setup / handle settings
const setup = async (options, resolve, reject) => {
  // console.log('setup');
  settings = options;
  settings.resolve = resolve;
  settings.reject = reject;
  if (settings.zip) {
    await setup_zip();
  } else {
    throw new Error('No valid output destination');
  }
};

// prepare a zip stream for the destination output
const setup_zip = async () => {
  // console.log('setup_zip');
  try {
    archive_out = fs.createWriteStream(path.resolve(settings.zip));
    archive = archiver('zip');
    archive.pipe(archive_out);
    // event listener to keep track of entries into the zip stream
    archive.on('entry', () => {
      archive_entries_processed += 1;
      if (archive_entries_processed === archive_entries_added) {
        // console.log('all zipped entries processed');
        archive.finalize();
      }
    });
    // event listener to handle when the write stream is closed
    archive_out.on('close', () => {
      // only resolve once the stream has been closed
      // console.log('write stream has closed');
      settings.resolve(documents_counter);
    });
    // archive listener to handle errors
    archive.on('error', (err) => {
      settings.reject(err);
      console.log('Archive Error:', err);
    });
    return;
  } catch (e) {
    console.log('Error: setup_zip', e);
  }
};

// gets the available model yaml files from the current working directory
const get_models = () => new Promise((resolve, reject) => {
  // console.log('get_models');
  try {
    fs.readdir(process.cwd(), (err, files) => {
      if (err) {
        throw err;
      } else {
        files = files.filter((file) => {
          return file.match(/\.yaml$/i);
        });
        if (!files.length) {
          reject('No models found');
        } else {
          resolve(files);
        }
      }
    });
  } catch (e) {
    console.log('Error: get_models', e);
    reject(e);
  }
});

// loop over all of the found yaml files and load them
const load_models = async (files) => {
  // console.log('load_models');
  let tmp = [];
  model_count = files.length;
  files.forEach((file) => {
    tmp.push(load_yaml_file(file));
  });
  return await Promise.all(tmp);
};

// load and conver a yaml file to a json object
const load_yaml_file = (file) => new Promise((resolve, reject) => {
  // console.log('load_yaml_file');
  yaml.load(path.join(process.cwd(), file), (result) => {
    if (result) {
      // console.log(JSON.stringify(result, null, 2));
      if (result.name) {
        models[result.name] = result; // add the parsed model to the global object
        resolve();
      } else {
        reject('Model must have a "name" property');
      }
    } else {
      reject('Invalid YAML file');
    }
  });
});

// parse each of the model properties for a data block and prepare any function calls
const parse_models = async () => {
  // console.log('parse_models');
  try {
    for (let model in models) { // loop over each model
      if (models.hasOwnProperty(model)) {
        for (let property in models[model].properties) { // loop over each of the properties
          // if there is a build property prepare the function
          if (models[model].properties[property].data.build) {
            models[model].properties[property].data.build = new Function(
              'documents', 'globals', 'faker', 'chance',
              models[model].properties[property].data.build
            );
          }
          // if there is a transform property prepare the function
          if (models[model].properties[property].data.transform) {
            models[model].properties[property].data.transform = new Function(
              'current_value', 'current_document', 'faker', 'chance',
              models[model].properties[property].data.transform
            );
          }
        }
      }
    }
    return;
  } catch (e) {
    console.log('Error: parse_models', e);
    throw e;
  }
};

// resolve the dependencies and establish the order the models should be parsed in
const resolve_dependencies = async () => {
  // console.log('resolve_dependencies');
  try {
    let counter = 0;
    // continue looping until all dependencies are resolve or we have looped (model_count * 5) times at which point
    // not all dependencies could be resolved and we will just error to prevent an infinte loop
    while (counter < model_count * 5 && model_order.length < model_count) {
      counter += 1;
      for (let model in models) {
        // if there are dependencies, determine if all of the dependencies have already been added to the order
        if (models[model].data.dependencies) {
          if (check_dependencies(models[model].data.dependencies)) {
            add_model_order(model);
          }
        } else { // there are no dependencies add it to the order
          add_model_order(model);
        }
      }
    }
    if (model_order.length !== model_count) {
      // update error to include which models could not be resolved
      throw new Error('Model dependencies could not be resolved.');
    } else {
      console.log('Models will be generated in the following order: %s', model_order.join(', '));
      return;
    }
  } catch (e) {
    throw new Error(`Error: resolve_dependencies ${e.message}`);
  }
};

// determines if all dependencies have been resolved or not
const check_dependencies = (dependencies) => {
  let resolved = 0;
  // loop over each of the models dependencies and check if its dependencies have been resolved
  for (let i = 0; i < dependencies.length; i++) {
    resolved += model_order.indexOf(dependencies[i]) !== -1 ? 1 : 0;
  }
  return resolved === dependencies.length;
};

// adds a model to the run order if it has not already been added
const add_model_order = (model) => {
  if (model_order.indexOf(model) === -1) {
    model_order.push(model);
  }
  return;
};

const generate = async () => {
  // console.log('generate');
  // define a key based on the model path to hold the generated documents for the model
  for (let i = 0; i < model_order.length; i++) { // loop over each model and execute in order of dependency
    documents[model_order[i]] = [];
    await run(model_order[i]); // eslint-disable-line babel/no-await-in-loop
  }
  return;
};

// executes the building of a model
const run = async (model_name) => {
  // console.log('run', model_name);
  // define a key based on the model path to hold the generated documents for the model
  let builds = [];
  let number = Math.floor(Math.random() * models[model_name].data.max) + models[model_name].data.min;
  console.log(`Generating ${number} documents for ${model_name} model`);
  for (let i = 0; i < number; i++) { // loop over each model and execute in order of dependency
    builds.push(build(models[model_name]));
  }
  return await Promise
                .all(builds)
                .catch((e) => {
                  throw e;
                });
};

const build = async (current_model) => {
  try {
    documents_counter += 1;
    // generate the initial values
    let generated_document = await build_properties(current_model);
    generated_document = await build_transform(current_model, generated_document);
    documents[current_model.name].push(generated_document);
    await build_finalize(current_model, generated_document);
    return;
  } catch (e) {
    throw e;
  }
};

const build_properties = async (current_model) => {
  // console.log('build_properties');
  let doc = {};
  let key;
  try {
    // generate the initial values
    for (key in current_model.properties) {
      // if there is a faker block, attempt to fake the doc
      if (current_model.properties[key].data) {
        if (current_model.properties[key].data.fake) { // if we are generating fake doc
          doc[key] = faker.fake(current_model.properties[key].data.fake);
        } else if (current_model.properties[key].data.value) { // if there is a static value
          doc[key] = current_model.properties[key].data.value;
        } else if (current_model.properties[key].data.build) { // if there is a build function
          doc[key] = current_model.properties[key].data.build(documents, globals, faker, chance);
        } else { // nothing matched
          doc[key] = null;
        }
      } else { // there is not a faker block, but the key is defined so set it to null
        doc[key] = null;
      }
    }
    return doc;
  } catch (e) {
    throw new Error(`Error: Building Properties in Model: "${current_model.name}" for Key: "${key}", Reason: ${e.message}`);
    // reject(`Failed to build property "${key}" in model "${current_model.name}" Reason: ${e.message}`);
  }
};

const build_transform = async (current_model, generated_document) => {
  // console.log('build_transform');
  let key;
  try {
    // loop over the generated results
    for (key in generated_document) {
      // if there is a transform block
      if (current_model.properties[key].data && current_model.properties[key].data.transform) {
        generated_document[key] = current_model.properties[key].data.transform(generated_document[key], generated_document, faker, chance);
      }
      // if it is a number make sure it is treated as such
      if (generated_document[key] && 'number,integer,long'.indexOf(current_model.properties[key].type) !== -1) {
        generated_document[key] = parseInt(generated_document[key]);
      }
      // if it is a number make sure it is treated as such
      if (generated_document[key] && 'double,float'.indexOf(current_model.properties[key].type) !== -1) {
        generated_document[key] = parseFloat(generated_document[key]);
      }
    }
    return generated_document;
  } catch (e) {
    throw new Error(`Error: Transforming Properties in Model: "${current_model.name}" for Key: "${key}", Reason: ${e.message}`);
  }
};

const build_finalize = async (current_model, generated_document) => {
  // console.log('build_finalize');
  try {
    if (settings.zip) {
      await append_zip(
        current_model,
        JSON.stringify(generated_document, null, 2),
        generated_document[current_model.key] + '.json'
      );
    }
    return;
  } catch (e) {
    throw new Error(`Error: Finalizing Document in Model: "${current_model.name}", Reason: ${e.message}`);
  }
};

const append_zip = async (current_model, data, entry_name) => {
  try {
    archive_entries_added += 1;
    archive.append(
      data,
      {
        name: entry_name
      }
    );
    // resolve(data);
    return data;
  } catch (e) {
    console.log('Error: append_zip');
    console.log(data, entry_name);
    console.log(e);
    // reject(e);
  }
};

export default { start };
